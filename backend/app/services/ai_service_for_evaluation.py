"""
AI Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Evaluation ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
‡πÅ‡∏¢‡∏Å‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á raw response ‡∏à‡∏≤‡∏Å OpenAI

‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢ run_evaluation.py ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Å‡∏±‡∏ö ai_service.py ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å
"""

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import json
import os
from typing import Dict, List, Any

# Import models ‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

from app.models import TaxCalculationRequest, TaxCalculationResult
from app.config import settings


class AIServiceForEvaluation:
    """
    AI Service ‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Evaluation
    
    ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å ai_service.py ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å:
    1. ‡πÅ‡∏™‡∏î‡∏á raw response ‡∏à‡∏≤‡∏Å OpenAI
    2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å raw response ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
    3. ‡πÅ‡∏™‡∏î‡∏á prompt ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ
    4. ‡∏°‡∏µ verbose logging ‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug
    """
    
    def __init__(self, verbose: bool = True, save_to_file: bool = True):
        """
        Args:
            verbose: ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° debug ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            save_to_file: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å raw response ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        """
        self.llm = ChatOpenAI(
            model=settings.openai_model,
            temperature=settings.openai_temperature,
            openai_api_key=settings.openai_api_key
        )
        self.verbose = verbose
        self.save_to_file = save_to_file
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö logs
        if self.save_to_file:
            self.log_dir = Path(__file__).parent.parent.parent / "evaluation_logs"
            self.log_dir.mkdir(exist_ok=True)
    
    def generate_tax_optimization_prompt(
        self, 
        request: TaxCalculationRequest,
        tax_result: TaxCalculationResult,
        retrieved_context: str
    ) -> str:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏î‡πâ)
        
        **‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ prompt ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å**
        """
        gross = tax_result.gross_income
        max_rmf = min(gross * 0.30, 500000)
        max_ssf = min(gross * 0.30, 200000)
        max_pension = min(gross * 0.15, 200000)
        
        remaining_rmf = max_rmf - request.rmf
        remaining_ssf = max_ssf - request.ssf
        remaining_pension = max_pension - request.pension_insurance
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏†‡∏≤‡∏©‡∏µ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°
        taxable = tax_result.taxable_income
        if taxable <= 150000:
            marginal_rate = 0
        elif taxable <= 300000:
            marginal_rate = 5
        elif taxable <= 500000:
            marginal_rate = 10
        elif taxable <= 750000:
            marginal_rate = 15
        elif taxable <= 1000000:
            marginal_rate = 20
        elif taxable <= 2000000:
            marginal_rate = 25
        elif taxable <= 5000000:
            marginal_rate = 30
        else:
            marginal_rate = 35
        
        return f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏†‡∏≤‡∏©‡∏µ‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ‡∏õ‡∏µ 2568

===========================================
üìä ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
===========================================
‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏£‡∏ß‡∏°: {tax_result.gross_income:,.0f} ‡∏ö‡∏≤‡∏ó
‡πÄ‡∏á‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡∏™‡∏∏‡∏ó‡∏ò‡∏¥: {tax_result.taxable_income:,.0f} ‡∏ö‡∏≤‡∏ó
‡∏†‡∏≤‡∏©‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡πà‡∏≤‡∏¢: {tax_result.tax_amount:,.0f} ‡∏ö‡∏≤‡∏ó
‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏†‡∏≤‡∏©‡∏µ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {tax_result.effective_tax_rate}%
‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏†‡∏≤‡∏©‡∏µ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°: {marginal_rate}%
‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á: {request.risk_tolerance}

===========================================
üí∞ ‡∏Ñ‡πà‡∏≤‡∏•‡∏î‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß
===========================================
RMF: {request.rmf:,.0f} / {max_rmf:,.0f} ‡∏ö‡∏≤‡∏ó (‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {remaining_rmf:,.0f})
SSF: {request.ssf:,.0f} / {max_ssf:,.0f} ‡∏ö‡∏≤‡∏ó (‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {remaining_ssf:,.0f})
‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ö‡∏≥‡∏ô‡∏≤‡∏ç: {request.pension_insurance:,.0f} / {max_pension:,.0f} ‡∏ö‡∏≤‡∏ó (‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {remaining_pension:,.0f})
‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï: {request.life_insurance:,.0f} / 100,000 ‡∏ö‡∏≤‡∏ó
‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û: {request.health_insurance:,.0f} / 25,000 ‡∏ö‡∏≤‡∏ó
‡∏Å‡∏≠‡∏á‡∏ó‡∏∏‡∏ô PVD: {request.provident_fund:,.0f} ‡∏ö‡∏≤‡∏ó
‡πÄ‡∏á‡∏¥‡∏ô‡∏ö‡∏£‡∏¥‡∏à‡∏≤‡∏Ñ: {request.donation:,.0f} ‡∏ö‡∏≤‡∏ó

===========================================
üìö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Knowledge Base
===========================================
{retrieved_context}

===========================================
üéØ ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á
===========================================

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏†‡∏≤‡∏©‡∏µ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÑ‡∏î‡πâ:**
‡∏†‡∏≤‡∏©‡∏µ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î = investment_amount √ó {marginal_rate}%

**‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:**
1. ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÉ‡∏ô‡∏ß‡∏á‡πÄ‡∏á‡∏¥‡∏ô
2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏†‡∏≤‡∏©‡∏µ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
3. ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
4. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Knowledge Base ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

===========================================
üìù ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö (JSON Array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)
===========================================

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON Array ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô:

[
  {{
    "strategy": "‡∏•‡∏á‡∏ó‡∏∏‡∏ô RMF ‡πÄ‡∏û‡∏¥‡πà‡∏° 150,000 ‡∏ö‡∏≤‡∏ó (‡∏Å‡∏≠‡∏á‡∏ó‡∏∏‡∏ô‡∏ú‡∏™‡∏°)",
    "description": "‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÉ‡∏ô‡∏Å‡∏≠‡∏á‡∏ó‡∏∏‡∏ô RMF ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ú‡∏™‡∏°...",
    "investment_amount": 150000,
    "tax_saving": {int(150000 * marginal_rate / 100)},
    "risk_level": "medium",
    "expected_return_1y": 5.5,
    "expected_return_3y": 6.8,
    "expected_return_5y": 8.0,
    "pros": ["‡∏•‡∏î‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏µ‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á", "‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡∏î‡∏µ"],
    "cons": ["‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏∑‡∏≠‡∏à‡∏ô‡∏≠‡∏≤‡∏¢‡∏∏ 55 ‡∏õ‡∏µ", "‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á"]
  }}
]

‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏≠‡∏ö‡πÄ‡∏•‡∏¢:"""
    
    async def generate_recommendations(
        self,
        request: TaxCalculationRequest,
        tax_result: TaxCalculationResult,
        retrieved_context: str,
        test_case_id: int = 0
    ) -> tuple[list[dict], str]:
        """
        ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å OpenAI ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
        
        Returns:
            (recommendations, raw_response)
        """
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt
            prompt = self.generate_tax_optimization_prompt(
                request, tax_result, retrieved_context
            )
            
            # ‡πÅ‡∏™‡∏î‡∏á Prompt (‡∏ñ‡πâ‡∏≤ verbose)
            if self.verbose:
                print("\n" + "=" * 80)
                print("üì§ PROMPT SENT TO OPENAI:")
                print("=" * 80)
                print(prompt[:1000] + "...[truncated]" if len(prompt) > 1000 else prompt)
                print("=" * 80 + "\n")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
            if self.save_to_file:
                prompt_file = self.log_dir / f"prompt_test_case_{test_case_id}.txt"
                with open(prompt_file, 'w', encoding='utf-8') as f:
                    f.write(prompt)
                if self.verbose:
                    print(f"üíæ Saved prompt to: {prompt_file}\n")
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å OpenAI
            if self.verbose:
                print("ü§ñ Calling OpenAI API...")
            
            response = await self.llm.ainvoke(prompt)
            raw_response = response.content
            
            # ‡πÅ‡∏™‡∏î‡∏á Raw Response
            if self.verbose:
                print("\n" + "=" * 80)
                print("üì• RAW RESPONSE FROM OPENAI:")
                print("=" * 80)
                print(raw_response)
                print("=" * 80 + "\n")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Raw Response ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
            if self.save_to_file:
                response_file = self.log_dir / f"raw_response_test_case_{test_case_id}.txt"
                with open(response_file, 'w', encoding='utf-8') as f:
                    f.write(raw_response)
                if self.verbose:
                    print(f"üíæ Saved raw response to: {response_file}\n")
            
            # Parse JSON
            recommendations_text = raw_response.strip()
            
            # ‡∏•‡∏ö markdown code blocks ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if recommendations_text.startswith("```json"):
                recommendations_text = recommendations_text[7:]
                if self.verbose:
                    print("üîß Removed ```json prefix")
            if recommendations_text.startswith("```"):
                recommendations_text = recommendations_text[3:]
                if self.verbose:
                    print("üîß Removed ``` prefix")
            if recommendations_text.endswith("```"):
                recommendations_text = recommendations_text[:-3]
                if self.verbose:
                    print("üîß Removed ``` suffix")
            
            recommendations = json.loads(recommendations_text.strip())
            
            # ‡πÅ‡∏™‡∏î‡∏á Parsed Result
            if self.verbose:
                print("\n" + "=" * 80)
                print("üìä PARSED RECOMMENDATIONS:")
                print("=" * 80)
                print(json.dumps(recommendations, indent=2, ensure_ascii=False))
                print("=" * 80 + "\n")
                print(f"‚úÖ Successfully parsed {len(recommendations)} recommendations\n")
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Parsed Result ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
            if self.save_to_file:
                parsed_file = self.log_dir / f"parsed_recommendations_test_case_{test_case_id}.json"
                with open(parsed_file, 'w', encoding='utf-8') as f:
                    json.dump(recommendations, f, indent=2, ensure_ascii=False)
                if self.verbose:
                    print(f"üíæ Saved parsed recommendations to: {parsed_file}\n")
            
            return recommendations, raw_response
            
        except json.JSONDecodeError as e:
            print(f"\n‚ùå JSON Parse Error: {e}")
            print(f"\nüìÑ Raw Response was:")
            print("=" * 80)
            print(raw_response)
            print("=" * 80)
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å error
            if self.save_to_file:
                error_file = self.log_dir / f"error_test_case_{test_case_id}.txt"
                with open(error_file, 'w', encoding='utf-8') as f:
                    f.write(f"JSON Parse Error: {e}\n\n")
                    f.write("Raw Response:\n")
                    f.write(raw_response)
                print(f"\nüíæ Saved error to: {error_file}\n")
            
            # Return fallback
            return self._get_fallback_recommendations(request, tax_result), raw_response
            
        except Exception as e:
            print(f"\n‚ùå AI Service Error: {e}")
            import traceback
            traceback.print_exc()
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å error
            if self.save_to_file:
                error_file = self.log_dir / f"error_test_case_{test_case_id}.txt"
                with open(error_file, 'w', encoding='utf-8') as f:
                    f.write(f"Error: {e}\n\n")
                    f.write(traceback.format_exc())
                print(f"\nüíæ Saved error to: {error_file}\n")
            
            return self._get_fallback_recommendations(request, tax_result), ""
    
    def _get_fallback_recommendations(
        self,
        request: TaxCalculationRequest,
        tax_result: TaxCalculationResult
    ) -> list[dict]:
        """
        ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Å‡∏£‡∏ì‡∏µ AI ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        """
        if self.verbose:
            print("\n‚ö†Ô∏è  Using fallback recommendations...\n")
        
        gross = tax_result.gross_income
        max_rmf = min(gross * 0.30, 500000)
        remaining_rmf = max_rmf - request.rmf
        
        marginal_rate = 20  # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì
        
        recommendations = []
        
        if remaining_rmf > 0:
            amount = min(remaining_rmf, 100000)
            recommendations.append({
                "strategy": f"‡∏•‡∏á‡∏ó‡∏∏‡∏ô RMF ‡πÄ‡∏û‡∏¥‡πà‡∏° {amount:,.0f} ‡∏ö‡∏≤‡∏ó",
                "description": "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏£‡∏≠‡∏á: ‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡πÉ‡∏ô‡∏Å‡∏≠‡∏á‡∏ó‡∏∏‡∏ô RMF",
                "investment_amount": amount,
                "tax_saving": int(amount * marginal_rate / 100),
                "risk_level": "medium",
                "expected_return_1y": 5.0,
                "expected_return_3y": 6.5,
                "expected_return_5y": 8.0,
                "pros": ["‡∏•‡∏î‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏µ", "‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡∏î‡∏µ"],
                "cons": ["‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏∑‡∏≠‡∏à‡∏ô‡∏≠‡∏≤‡∏¢‡∏∏ 55 ‡∏õ‡∏µ"]
            })
        
        return recommendations


# ==========================================
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
# ==========================================

if __name__ == "__main__":
    import asyncio
    from app.services.tax_service import TaxService
    
    print("üß™ Testing AIServiceForEvaluation\n")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á service
    ai_service = AIServiceForEvaluation(verbose=True, save_to_file=True)
    tax_service = TaxService()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á test request
    request = TaxCalculationRequest(
        gross_income=600000,
        personal_deduction=60000,
        life_insurance=50000,
        health_insurance=15000,
        provident_fund=50000,
        rmf=0,
        ssf=0,
        pension_insurance=0,
        donation=0,
        risk_tolerance="medium"
    )
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏†‡∏≤‡∏©‡∏µ
    tax_result = tax_service.calculate_tax(request)
    
    # Mock context
    context = """
    RMF ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏î‡∏´‡∏¢‡πà‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏µ‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 30% ‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ
    ‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏∑‡∏≠‡∏à‡∏ô‡∏≠‡∏≤‡∏¢‡∏∏ 55 ‡∏õ‡∏µ
    ‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 5-8% ‡∏ï‡πà‡∏≠‡∏õ‡∏µ
    """
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å AI
    async def test():
        recommendations, raw_response = await ai_service.generate_recommendations(
            request, tax_result, context, test_case_id=999
        )
        
        print("\n" + "=" * 80)
        print("‚úÖ TEST COMPLETED!")
        print("=" * 80)
        print(f"üìä Got {len(recommendations)} recommendations")
        print(f"üìù Raw response length: {len(raw_response)} characters")
        print(f"üíæ Files saved to: {ai_service.log_dir}")
        print("=" * 80 + "\n")
    
    asyncio.run(test())